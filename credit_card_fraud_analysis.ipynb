{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Processing using PySpark\n",
    "This notebook loads and processes raw JSON data related to credit card transactions and prepares it for fraud analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required PySpark modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"CreditCardFraudProcessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw JSON Data\n",
    "We load the raw JSON data and inspect its schema and a few sample records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-json",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw JSON file\n",
    "df_raw = spark.read.json(\"path/to/data.json\")  # Replace with actual path\n",
    "df_raw.printSchema()\n",
    "df_raw.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse `personal_detail` JSON String\n",
    "The `personal_detail` field contains nested JSON, so we parse it using a defined schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-detail-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for personal_detail\n",
    "personal_schema = StructType([\n",
    "    StructField(\"person_name\", StringType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"address\", StringType()),\n",
    "    StructField(\"lat\", StringType()),\n",
    "    StructField(\"long\", StringType()),\n",
    "    StructField(\"city_pop\", StringType()),\n",
    "    StructField(\"job\", StringType()),\n",
    "    StructField(\"dob\", StringType())\n",
    "])\n",
    "\n",
    "# Parse the personal_detail JSON string\n",
    "df = df_raw.withColumn(\"personal_detail_json\", from_json(\"personal_detail\", personal_schema)).drop(\"personal_detail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Nested Address Field\n",
    "We further parse the `address` field within `personal_detail`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "address-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define address schema\n",
    "address_schema = StructType([\n",
    "    StructField(\"street\", StringType()),\n",
    "    StructField(\"city\", StringType()),\n",
    "    StructField(\"state\", StringType()),\n",
    "    StructField(\"zip\", StringType())\n",
    "])\n",
    "\n",
    "# Parse the address field\n",
    "df = df.withColumn(\"address_json\", from_json(\"personal_detail_json.address\", address_schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten Nested Fields\n",
    "We extract and flatten the relevant fields to prepare for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flatten-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and flatten fields\n",
    "df = df \\\n",
    "    .withColumn(\"first\", split(col(\"personal_detail_json.person_name\"), \"[,@/]\")[0]) \\\n",
    "    .withColumn(\"last\", split(col(\"personal_detail_json.person_name\"), \"[,@/]\")[1]) \\\n",
    "    .withColumn(\"gender\", col(\"personal_detail_json.gender\")) \\\n",
    "    .withColumn(\"dob\", col(\"personal_detail_json.dob\")) \\\n",
    "    .withColumn(\"street\", col(\"address_json.street\")) \\\n",
    "    .withColumn(\"city\", col(\"address_json.city\")) \\\n",
    "    .withColumn(\"state\", col(\"address_json.state\")) \\\n",
    "    .withColumn(\"zip\", col(\"address_json.zip\")) \\\n",
    "    .withColumn(\"lat\", col(\"personal_detail_json.lat\").cast(\"double\")) \\\n",
    "    .withColumn(\"long\", col(\"personal_detail_json.long\").cast(\"double\")) \\\n",
    "    .withColumn(\"city_pop\", col(\"personal_detail_json.city_pop\").cast(\"int\")) \\\n",
    "    .withColumn(\"job\", col(\"personal_detail_json.job\")) \\\n",
    "    .drop(\"personal_detail_json\", \"address_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Epoch Timestamps\n",
    "Convert merchant-related timestamps from epoch microseconds to readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timestamp-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert epoch microseconds to timestamp\n",
    "def convert_epoch_microseconds(colname):\n",
    "    return from_utc_timestamp((col(colname) / 1000000).cast(\"timestamp\"), \"Asia/Kuala_Lumpur\")\n",
    "\n",
    "df = df \\\n",
    "    .withColumn(\"trans_date_trans_time\", to_timestamp(\"trans_date_trans_time\")) \\\n",
    "    .withColumn(\"merch_last_update_time\", convert_epoch_microseconds(\"merch_last_update_time\")) \\\n",
    "    .withColumn(\"merch_eff_time\", convert_epoch_microseconds(\"merch_eff_time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Credit Card Numbers\n",
    "Apply SHA-256 to protect sensitive credit card numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mask-cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask sensitive credit card number\n",
    "df = df.withColumn(\"cc_num_masked\", sha2(col(\"cc_num\"), 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Sample Processed Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"first\", \"last\", \"gender\", \"amt\", \"category\", \"is_fraud\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Fraud Distribution\n",
    "We use Seaborn to visualize fraud counts by merchant category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas for visualization\n",
    "pdf = df.select(\"category\", \"amt\", \"is_fraud\").toPandas()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(data=pdf, x=\"category\", hue=\"is_fraud\")\n",
    "plt.title(\"Fraud Cases by Category\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
